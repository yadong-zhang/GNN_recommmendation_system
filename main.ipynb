{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Neural Networks for Social Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create torch dataset and preprocessing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(Dataset):\n",
    "    def __init__(self, data, u_items_list, u_user_list, u_users_items_list, i_users_list):\n",
    "        self.data = data\n",
    "        self.u_items_list = u_items_list\n",
    "        self.u_users_list = u_user_list\n",
    "        self.u_users_items_list = u_users_items_list\n",
    "        self.i_users_list = i_users_list\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        uid = self.data[index][0]\n",
    "        iid = self.data[index][1]\n",
    "        label = self.data[index][2]\n",
    "        u_items = self.u_items_list[uid]\n",
    "        u_users = self.u_users_list[uid]\n",
    "        u_users_items = self.u_users_items_list[uid]\n",
    "        i_users = self.i_users_list[iid]\n",
    "\n",
    "        return (uid, iid, label), u_items, u_users, u_users_items, i_users\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "truncate_len = 45\n",
    "\n",
    "def collate_fn(batch_data):\n",
    "\n",
    "    uids, iids, labels = [], [], []\n",
    "    u_items, u_users, u_users_items, i_users = [], [], [], []\n",
    "    u_items_len, u_users_len, i_users_len = [], [], []\n",
    "\n",
    "    for data, u_items_u, u_users_u, u_users_items_u, i_users_i in batch_data:\n",
    "\n",
    "        (uid, iid, label) = data\n",
    "        uids.append(uid)\n",
    "        iids.append(iid)\n",
    "        labels.append(label)\n",
    "\n",
    "        # user-items\n",
    "        if len(u_items_u) <= truncate_len:\n",
    "            u_items.append(u_items_u)\n",
    "        else:\n",
    "            u_items.append(random.sample(u_items_u, truncate_len))\n",
    "        u_items_len.append(min(len(u_items_u), truncate_len))\n",
    "        \n",
    "        # user-users and user-users-items\n",
    "        if len(u_users_u) <= truncate_len:\n",
    "            u_users.append(u_users_u)\n",
    "            u_u_items = [] \n",
    "            for uui in u_users_items_u:\n",
    "                if len(uui) < truncate_len:\n",
    "                    u_u_items.append(uui)\n",
    "                else:\n",
    "                    u_u_items.append(random.sample(uui, truncate_len))\n",
    "            u_users_items.append(u_u_items)\n",
    "        else:\n",
    "            sample_index = random.sample(list(range(len(u_users_u))), truncate_len)\n",
    "            u_users.append([u_users_u[si] for si in sample_index])\n",
    "\n",
    "            u_users_items_u_tr = [u_users_items_u[si] for si in sample_index]\n",
    "            u_u_items = [] \n",
    "            for uui in u_users_items_u_tr:\n",
    "                if len(uui) < truncate_len:\n",
    "                    u_u_items.append(uui)\n",
    "                else:\n",
    "                    u_u_items.append(random.sample(uui, truncate_len))\n",
    "            u_users_items.append(u_u_items)\n",
    "\n",
    "        u_users_len.append(min(len(u_users_u), truncate_len))\t\n",
    "\n",
    "        # item-users\n",
    "        if len(i_users_i) <= truncate_len:\n",
    "            i_users.append(i_users_i)\n",
    "        else:\n",
    "            i_users.append(random.sample(i_users_i, truncate_len))\n",
    "        i_users_len.append(min(len(i_users_i), truncate_len))\n",
    "\n",
    "    batch_size = len(batch_data)\n",
    "\n",
    "    # padding\n",
    "    u_items_maxlen = max(u_items_len)\n",
    "    u_users_maxlen = max(u_users_len)\n",
    "    i_users_maxlen = max(i_users_len)\n",
    "    \n",
    "    u_item_pad = torch.zeros([batch_size, u_items_maxlen, 2], dtype=torch.long)\n",
    "    for i, ui in enumerate(u_items):\n",
    "        u_item_pad[i, :len(ui), :] = torch.LongTensor(ui)\n",
    "    \n",
    "    u_user_pad = torch.zeros([batch_size, u_users_maxlen], dtype=torch.long)\n",
    "    for i, uu in enumerate(u_users):\n",
    "        u_user_pad[i, :len(uu)] = torch.LongTensor(uu)\n",
    "    \n",
    "    u_user_item_pad = torch.zeros([batch_size, u_users_maxlen, u_items_maxlen, 2], dtype=torch.long)\n",
    "    for i, uu_items in enumerate(u_users_items):\n",
    "        for j, ui in enumerate(uu_items):\n",
    "            u_user_item_pad[i, j, :len(ui), :] = torch.LongTensor(ui)\n",
    "\n",
    "    i_user_pad = torch.zeros([batch_size, i_users_maxlen, 2], dtype=torch.long)\n",
    "    for i, iu in enumerate(i_users):\n",
    "        i_user_pad[i, :len(iu), :] = torch.LongTensor(iu)\n",
    "\n",
    "    uids = torch.LongTensor(uids)\n",
    "    iids = torch.LongTensor(iids)\n",
    "    labels = torch.FloatTensor(labels)\n",
    "\n",
    "    return uids, iids, labels, u_item_pad, u_user_pad, u_user_item_pad, i_user_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(MLP, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim//2, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim//2, output_dim, bias=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "class Aggregator(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(Aggregator, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(input_dim, output_dim, bias=True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.mlp(x)\n",
    "\n",
    "\n",
    "class UserModel(nn.Module):\n",
    "    def __init__(self, emb_dim, user_emb, item_emb, rating_emb):\n",
    "        super(UserModel, self).__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.user_emb = user_emb\n",
    "        self.item_emb = item_emb\n",
    "        self.rating_emb = rating_emb\n",
    "\n",
    "        self.g_v = MLP(2*self.emb_dim, self.emb_dim)\n",
    "        \n",
    "        self.user_item_attn = MLP(2*self.emb_dim, 1)\n",
    "        self.aggr_items = Aggregator(self.emb_dim, self.emb_dim)\n",
    "\n",
    "        self.user_user_attn = MLP(2*self.emb_dim, 1)\n",
    "        self.aggr_neighbors = Aggregator(self.emb_dim, self.emb_dim)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(2*self.emb_dim, self.emb_dim, bias = True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.emb_dim, self.emb_dim, bias = True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.emb_dim, self.emb_dim, bias = True),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.eps = 1e-10\n",
    "\n",
    "    def forward(self, uids, u_item_pad, u_user_pad, u_user_item_pad):\n",
    "\n",
    "        q_a = self.item_emb(u_item_pad[:,:,0])\n",
    "        u_item_er = self.rating_emb(u_item_pad[:,:,1])\n",
    "        x_ia = self.g_v(torch.cat([q_a, u_item_er], dim=2).view(-1, 2*self.emb_dim)).view(q_a.size())\n",
    "        mask_u = torch.where(u_item_pad[:,:,0]>0, torch.tensor([1.], device=self.device), torch.tensor([0.], device=self.device))\n",
    "        p_i = mask_u.unsqueeze(2).expand_as(x_ia) * self.user_emb(uids).unsqueeze(1).expand_as(x_ia)\n",
    "        alpha = self.user_item_attn(torch.cat([x_ia, p_i], dim=2).view(-1, 2*self.emb_dim)).view(mask_u.size())\n",
    "        alpha = torch.exp(alpha)*mask_u\n",
    "        alpha = alpha / (torch.sum(alpha, 1).unsqueeze(1).expand_as(alpha) + self.eps)\n",
    "        h_iI = self.aggr_items(torch.sum(alpha.unsqueeze(2).expand_as(x_ia) * x_ia, 1))\n",
    "\n",
    "\n",
    "        q_a_s = self.item_emb(u_user_item_pad[:,:,:,0])\n",
    "        u_user_item_er = self.rating_emb(u_user_item_pad[:,:,:,1])\n",
    "        x_ia_s = self.g_v(torch.cat([q_a_s, u_user_item_er], dim=2).view(-1, 2*self.emb_dim)).view(q_a_s.size())\n",
    "        mask_s = torch.where(u_user_item_pad[:,:,:,0]>0, torch.tensor([1.], device=self.device), torch.tensor([0.], device=self.device))\n",
    "        p_i_s = mask_s.unsqueeze(3).expand_as(x_ia_s) * self.user_emb(u_user_pad).unsqueeze(2).expand_as(x_ia_s)\n",
    "        alpha_s = self.user_item_attn(torch.cat([x_ia_s, p_i_s], dim=3).view(-1, 2*self.emb_dim)).view(mask_s.size())\n",
    "        alpha_s = torch.exp(alpha_s)*mask_s\n",
    "        alpha_s = alpha_s / (torch.sum(alpha_s, 2).unsqueeze(2).expand_as(alpha_s) + self.eps)\n",
    "        h_oI_temp = torch.sum(alpha_s.unsqueeze(3).expand_as(x_ia_s) * x_ia_s, 2)\n",
    "        h_oI = self.aggr_items(h_oI_temp.view(-1, self.emb_dim)).view(h_oI_temp.size())\n",
    "        \n",
    "        beta = self.user_user_attn(torch.cat([h_oI, self.user_emb(u_user_pad)], dim = 2).view(-1, 2 * self.emb_dim)).view(u_user_pad.size())\n",
    "        mask_su = torch.where(u_user_pad > 0, torch.tensor([1.], device=self.device), torch.tensor([0.], device=self.device))\n",
    "        beta = torch.exp(beta) * mask_su\n",
    "        beta = beta / (torch.sum(beta, 1).unsqueeze(1).expand_as(beta) + self.eps)\n",
    "        h_iS = self.aggr_neighbors(torch.sum(beta.unsqueeze(2).expand_as(h_oI) * h_oI, 1))\n",
    "\n",
    "        h_i = self.mlp(torch.cat([h_iI, h_iS], dim = 1))\n",
    "\n",
    "        return h_i\n",
    "\n",
    "\n",
    "class ItemModel(nn.Module):\n",
    "    def __init__(self, emb_dim, user_emb, item_emb, rating_emb):\n",
    "        super(ItemModel, self).__init__()\n",
    "        self.emb_dim = emb_dim\n",
    "        self.user_emb = user_emb\n",
    "        self.item_emb = item_emb\n",
    "        self.rating_emb = rating_emb\n",
    "\n",
    "        self.g_u = MLP(2*self.emb_dim, self.emb_dim)\n",
    "\n",
    "        self.item_users_attn = MLP(2*self.emb_dim, 1)\n",
    "        self.aggr_users = Aggregator(self.emb_dim, self.emb_dim)\n",
    "\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        self.eps = 1e-10\n",
    "    \n",
    "    def forward(self, iids, i_user_pad):\n",
    "\n",
    "        p_t = self.user_emb(i_user_pad[:,:,0])\n",
    "        i_user_er = self.rating_emb(i_user_pad[:,:,1])\n",
    "        mask_i = torch.where(i_user_pad[:,:,0] > 0, torch.tensor([1.], device=self.device), torch.tensor([0.], device=self.device))\n",
    "        f_jt = self.g_u(torch.cat([p_t, i_user_er], dim = 2).view(-1, 2 * self.emb_dim)).view(p_t.size())\n",
    "        q_j = mask_i.unsqueeze(2).expand_as(f_jt) * self.item_emb(iids).unsqueeze(1).expand_as(f_jt)\n",
    "        mu_jt = self.item_users_attn(torch.cat([f_jt, q_j], dim = 2).view(-1, 2 * self.emb_dim)).view(mask_i.size())\n",
    "        mu_jt = torch.exp(mu_jt) * mask_i\n",
    "        mu_jt = mu_jt / (torch.sum(mu_jt, 1).unsqueeze(1).expand_as(mu_jt) + self.eps)\n",
    "        \n",
    "        z_j = self.aggr_users(torch.sum(mu_jt.unsqueeze(2).expand_as(f_jt) * f_jt, 1))\n",
    "\n",
    "        return z_j\n",
    "        \n",
    "    \n",
    "class GraphRec(nn.Module):\n",
    "    def __init__(self, n_users, n_items, n_ratings, emb_dim = 64):\n",
    "        super(GraphRec, self).__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.n_ratings = n_ratings\n",
    "        self.emb_dim = emb_dim\n",
    "\n",
    "        self.user_emb = nn.Embedding(self.n_users, self.emb_dim, padding_idx=0)\n",
    "        self.item_emb = nn.Embedding(self.n_items, self.emb_dim, padding_idx=0)\n",
    "        self.rating_emb = nn.Embedding(self.n_ratings, self.emb_dim, padding_idx=0)\n",
    "\n",
    "        self.user_model = UserModel(self.emb_dim, self.user_emb, self.item_emb, self.rating_emb)\n",
    "        self.item_model = ItemModel(self.emb_dim, self.user_emb, self.item_emb, self.rating_emb)\n",
    "\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(2*self.emb_dim, self.emb_dim, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.emb_dim, self.emb_dim, bias=True),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.emb_dim, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, uids, iids, u_item_pad, u_user_pad, u_user_item_pad, i_user_pad):\n",
    "\n",
    "        h_i = self.user_model(uids, u_item_pad, u_user_pad, u_user_item_pad)\n",
    "        z_j = self.item_model(iids, i_user_pad)\n",
    "\n",
    "        r_ij = self.mlp(torch.cat([h_i, z_j], dim=1))\n",
    "\n",
    "        return r_ij"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device - cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('device - ' + str(device))\n",
    "batch_size = 128\n",
    "embed_dim = 64\n",
    "learning_rate = 0.001\n",
    "n_epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read dataset and preprocess it to form batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/dataset_epinions.pkl', 'rb') as f:\n",
    "    train_set = pickle.load(f)\n",
    "    valid_set = pickle.load(f)\n",
    "    test_set = pickle.load(f)\n",
    "\n",
    "with open('data/list_epinions.pkl', 'rb') as f:\n",
    "    u_items_list = pickle.load(f)\n",
    "    u_users_list = pickle.load(f)\n",
    "    u_users_items_list = pickle.load(f)\n",
    "    i_users_list = pickle.load(f)\n",
    "    (user_count, item_count, rate_count) = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = GraphDataset(train_set, u_items_list, u_users_list, u_users_items_list, i_users_list)\n",
    "valid_data = GraphDataset(valid_set, u_items_list, u_users_list, u_users_items_list, i_users_list)\n",
    "test_data = GraphDataset(test_set, u_items_list, u_users_list, u_users_items_list, i_users_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_data:\n",
    "    for j in i:\n",
    "        print(j)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_data, batch_size = batch_size, shuffle = True, collate_fn = collate_fn)\n",
    "valid_loader = DataLoader(valid_data, batch_size = batch_size, shuffle = False, collate_fn = collate_fn)\n",
    "test_loader = DataLoader(test_data, batch_size = batch_size, shuffle = False, collate_fn = collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5704"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in train_loader:\n",
    "    for j in i:\n",
    "        print(j)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model and set up training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphRec(user_count+1, item_count+1, rate_count+1, embed_dim).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.RMSprop(model.parameters(), learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 4, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [08:30<00:00,  5.58it/s]\n",
      "100%|██████████| 357/357 [00:48<00:00,  7.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 validation: MAE: 2.1474, RMSE: 4.8366, Best MAE: 2.1474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [08:36<00:00,  5.53it/s]\n",
      "100%|██████████| 357/357 [00:42<00:00,  8.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 validation: MAE: 1.7126, RMSE: 4.5229, Best MAE: 1.7126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [08:01<00:00,  5.92it/s]\n",
      "100%|██████████| 357/357 [00:45<00:00,  7.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 validation: MAE: 1.7524, RMSE: 4.3608, Best MAE: 1.7126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [07:57<00:00,  5.97it/s]\n",
      "100%|██████████| 357/357 [00:43<00:00,  8.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 validation: MAE: 1.4650, RMSE: 4.1344, Best MAE: 1.4650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [08:14<00:00,  5.76it/s]\n",
      "100%|██████████| 357/357 [00:41<00:00,  8.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 validation: MAE: 1.4697, RMSE: 4.1269, Best MAE: 1.4650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [07:32<00:00,  6.30it/s]\n",
      "100%|██████████| 357/357 [00:46<00:00,  7.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 validation: MAE: 1.4452, RMSE: 4.1138, Best MAE: 1.4452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [07:42<00:00,  6.17it/s]\n",
      "100%|██████████| 357/357 [00:40<00:00,  8.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 validation: MAE: 1.4397, RMSE: 4.1021, Best MAE: 1.4397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [07:23<00:00,  6.43it/s]\n",
      "100%|██████████| 357/357 [00:40<00:00,  8.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 validation: MAE: 1.4319, RMSE: 4.0940, Best MAE: 1.4319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [07:23<00:00,  6.43it/s]\n",
      "100%|██████████| 357/357 [00:39<00:00,  8.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 validation: MAE: 1.4318, RMSE: 4.0959, Best MAE: 1.4318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [07:25<00:00,  6.40it/s]\n",
      "100%|██████████| 357/357 [00:43<00:00,  8.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 validation: MAE: 1.4270, RMSE: 4.0926, Best MAE: 1.4270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [07:46<00:00,  6.12it/s]\n",
      "100%|██████████| 357/357 [00:40<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 validation: MAE: 1.4257, RMSE: 4.0904, Best MAE: 1.4257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [07:30<00:00,  6.33it/s]\n",
      "100%|██████████| 357/357 [00:41<00:00,  8.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 validation: MAE: 1.4278, RMSE: 4.0885, Best MAE: 1.4257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [08:01<00:00,  5.93it/s]\n",
      "100%|██████████| 357/357 [00:46<00:00,  7.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 validation: MAE: 1.4245, RMSE: 4.0888, Best MAE: 1.4245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [07:26<00:00,  6.38it/s]\n",
      "100%|██████████| 357/357 [00:40<00:00,  8.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 validation: MAE: 1.4244, RMSE: 4.0889, Best MAE: 1.4244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [07:45<00:00,  6.12it/s]\n",
      "100%|██████████| 357/357 [00:40<00:00,  8.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 validation: MAE: 1.4246, RMSE: 4.0888, Best MAE: 1.4244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [07:40<00:00,  6.19it/s]\n",
      "100%|██████████| 357/357 [00:43<00:00,  8.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 validation: MAE: 1.4247, RMSE: 4.0884, Best MAE: 1.4244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [07:31<00:00,  6.32it/s]\n",
      "100%|██████████| 357/357 [00:40<00:00,  8.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 validation: MAE: 1.4244, RMSE: 4.0888, Best MAE: 1.4244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [07:26<00:00,  6.38it/s]\n",
      "100%|██████████| 357/357 [00:42<00:00,  8.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 validation: MAE: 1.4246, RMSE: 4.0889, Best MAE: 1.4244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [07:24<00:00,  6.41it/s]\n",
      "100%|██████████| 357/357 [00:40<00:00,  8.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 validation: MAE: 1.4244, RMSE: 4.0887, Best MAE: 1.4244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [07:25<00:00,  6.40it/s]\n",
      "100%|██████████| 357/357 [00:40<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 validation: MAE: 1.4247, RMSE: 4.0892, Best MAE: 1.4244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [07:32<00:00,  6.30it/s]\n",
      "100%|██████████| 357/357 [00:44<00:00,  7.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21 validation: MAE: 1.4244, RMSE: 4.0890, Best MAE: 1.4244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [08:25<00:00,  5.64it/s]\n",
      "100%|██████████| 357/357 [00:50<00:00,  7.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22 validation: MAE: 1.4242, RMSE: 4.0888, Best MAE: 1.4242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [09:02<00:00,  5.25it/s]\n",
      "100%|██████████| 357/357 [00:50<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23 validation: MAE: 1.4243, RMSE: 4.0888, Best MAE: 1.4242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [09:06<00:00,  5.22it/s]\n",
      "100%|██████████| 357/357 [00:50<00:00,  7.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24 validation: MAE: 1.4243, RMSE: 4.0888, Best MAE: 1.4242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [09:08<00:00,  5.20it/s]\n",
      "100%|██████████| 357/357 [00:51<00:00,  6.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25 validation: MAE: 1.4243, RMSE: 4.0886, Best MAE: 1.4242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [09:05<00:00,  5.23it/s]\n",
      "100%|██████████| 357/357 [00:50<00:00,  7.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26 validation: MAE: 1.4245, RMSE: 4.0890, Best MAE: 1.4242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [09:01<00:00,  5.27it/s]\n",
      "100%|██████████| 357/357 [00:50<00:00,  7.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27 validation: MAE: 1.4247, RMSE: 4.0889, Best MAE: 1.4242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [09:02<00:00,  5.26it/s]\n",
      "100%|██████████| 357/357 [00:50<00:00,  7.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28 validation: MAE: 1.4244, RMSE: 4.0889, Best MAE: 1.4242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [09:04<00:00,  5.23it/s]\n",
      "100%|██████████| 357/357 [00:50<00:00,  7.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29 validation: MAE: 1.4244, RMSE: 4.0888, Best MAE: 1.4242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2852/2852 [09:02<00:00,  5.25it/s]\n",
      "100%|██████████| 357/357 [00:50<00:00,  7.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30 validation: MAE: 1.4244, RMSE: 4.0887, Best MAE: 1.4242\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "\n",
    "    # Training step\n",
    "    model.train()\n",
    "    s_loss = 0\n",
    "    for i, (uids, iids, labels, u_items, u_users, u_users_items, i_users) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "        uids = uids.to(device)\n",
    "        iids = iids.to(device)\n",
    "        labels = labels.to(device)\n",
    "        u_items = u_items.to(device)\n",
    "        u_users = u_users.to(device)\n",
    "        u_users_items = u_users_items.to(device)\n",
    "        i_users = i_users.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(uids, iids, u_items, u_users, u_users_items, i_users)\n",
    "        loss = criterion(outputs, labels.unsqueeze(1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_val = loss.item()\n",
    "        s_loss += loss_val\n",
    "\n",
    "        iter_num = epoch * len(train_loader) + i + 1\n",
    "\n",
    "    # Validate step\n",
    "    model.eval()\n",
    "    errors = []\n",
    "    with torch.no_grad():\n",
    "        for uids, iids, labels, u_items, u_users, u_users_items, i_users in tqdm(valid_loader):\n",
    "            uids = uids.to(device)\n",
    "            iids = iids.to(device)\n",
    "            labels = labels.to(device)\n",
    "            u_items = u_items.to(device)\n",
    "            u_users = u_users.to(device)\n",
    "            u_users_items = u_users_items.to(device)\n",
    "            i_users = i_users.to(device)\n",
    "            preds = model(uids, iids, u_items, u_users, u_users_items, i_users)\n",
    "            error = torch.abs(preds.squeeze(1) - labels)\n",
    "            errors.extend(error.data.cpu().numpy().tolist())\n",
    "    \n",
    "    mae = np.mean(errors)\n",
    "    rmse = np.sqrt(np.mean(np.power(errors, 2)))\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    ckpt_dict = {\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'optimizer': optimizer.state_dict()\n",
    "    }\n",
    "\n",
    "    torch.save(ckpt_dict, 'trained models epinions/latest_checkpoint.pth')\n",
    "\n",
    "    if epoch == 0:\n",
    "        best_mae = mae\n",
    "    elif mae < best_mae:\n",
    "        best_mae = mae\n",
    "        torch.save(ckpt_dict, 'trained models epinions/best_checkpoint_{}.pth'.format(embed_dim))\n",
    "\n",
    "    print('Epoch {} validation: MAE: {:.4f}, RMSE: {:.4f}, Best MAE: {:.4f}'.format(epoch+1, mae, rmse, best_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_dim = 64\n",
    "checkpoint = torch.load('trained models epinions/best_checkpoint_{}.pth'.format(embed_dim))\n",
    "model = GraphRec(user_count+1, item_count+1, rate_count+1, embed_dim).to(device)\n",
    "model.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 713/713 [04:41<00:00,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test: MAE: 1.2101, RMSE: 3.0421\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_errors = []\n",
    "with torch.no_grad():\n",
    "    for uids, iids, labels, u_items, u_users, u_users_items, i_users in tqdm(test_loader):\n",
    "        uids = uids.to(device)\n",
    "        iids = iids.to(device)\n",
    "        labels = labels.to(device)\n",
    "        u_items = u_items.to(device)\n",
    "        u_users = u_users.to(device)\n",
    "        u_users_items = u_users_items.to(device)\n",
    "        i_users = i_users.to(device)\n",
    "        preds = model(uids, iids, u_items, u_users, u_users_items, i_users)\n",
    "        error = torch.abs(preds.squeeze(1) - labels)\n",
    "        test_errors.extend(error.data.cpu().numpy().tolist())\n",
    "\n",
    "test_mae = np.mean(test_errors)\n",
    "test_rmse = np.sqrt(np.mean(np.power(test_errors, 2)))\n",
    "print('Test: MAE: {:.4f}, RMSE: {:.4f}'.format(test_mae, test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ec7d137c6e0bfe5aec1849c5c512dd0bf44cf2eb2fae9fc2de49724729b3d6c6"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('torch1.7': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
